{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = http://i1377.photobucket.com/albums/ah57/drmingle1/Jupyter%20-%20Healthcare%20Data%20Science/BosDataFestival2015_zpsqpbcvzw8.png alt=\"Matrix\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "# Finding Type II Diabetes In A Patient Population\n",
    "Given a year of EHR data for patients without Diabetes, we predict which patients will be diagnosed with Diabetes in the next year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##The Six Phases of a Data Science Workflow\n",
    "1. Business Understanding\n",
    "2. Data Understanding\n",
    "3. Data Preperation\n",
    "4. Modeling\n",
    "5. Evaluation\n",
    "6. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************************\n",
    "#Exercise 1\n",
    "\n",
    "Choose between A and B.\n",
    "***************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Scientist A**\n",
    "\n",
    "Company wants to predict patients with diabetes using EMR data.\n",
    "Company feels this will reduce cost significantly.\n",
    "\n",
    "We are going to use a logloss metric. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**===================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Scientist B**\n",
    "\n",
    "#PHASE I: Business Understanding\n",
    "\n",
    "####Determine Business Objectives\n",
    "1. *Background*\n",
    "    * **Organization**:\n",
    "        * ACME Healthcare\n",
    "    * **Problem Area**:\n",
    "        * Clinical Diagnosis\n",
    "        * As of 2014 there are 8.1 million people or 27.8% of people with diabetes who are undiagnosed. Total costs (both direct and indirect) is estimated to be $245 billion.\n",
    "        * Data Science needs to be promoted as a key way to assist the business.\n",
    "        * The organization is motivated to determine the patient population which has a high-likelihood of type II diabetes in order to offer better care for patients as well as reduce cost of care.\n",
    "        * Target groups we will work with are: chief medical officer, biostatisticians\n",
    "        * The organization is expecting to make use of a high-accuracy model to engage with physicians about their population\n",
    "    * **Current Solution**: \n",
    "        * *Description*: Hospital has rank ordered their patients based on a series of rules that have been identified by clinicians. The hospital is taking the top 5% of the patients who fall into that category and those cases are being reviewed by a physician to determine likelihood of being an underdiagnosed type II diabetic. \n",
    "        * *Advantages/Disadvantages*: Since the solution is more conventional the hospital feels more secure in their findings, although the process is prone to human error.  However, the current process is costly since it involves physicians and there is a significant lag in results as it takes six months to complete a single-iteration.\n",
    "        \n",
    "2. *Business objectives*\n",
    "    * Primary Objective: Given a year of EHR data for patients without Diabetes, aim to predict which patients will be diagnosed with diabetes in the next year.\n",
    "    * Other Objectives: What features are most predictive? The business does not want to create unnecessary alarm for their patient population. \n",
    "    * Benefits: The hospital expects that they will considerably reduce cost for the hospital by systematically discovering patients who may have fallen through cracks with regard to type II diabetes.\n",
    "    \n",
    "3. *Business success criteria*\n",
    "    * A successful and useful outcome for this Data Science project from the hospitals point of view is that they will experience their HCAP scores increase. Improved rankings bode well for the hospital. The potential for increase quality of care will aid the hospital as the healthcare environment swithces from fee-for-service to value-based care. \n",
    "    * Clinicians will assess the success of the program\n",
    "    * The hospital CFO will review the daily operations, budgeting, analytics, and oversight of expenses as it relates to this project. They will be looking for a 7% drop in cost of care within the first 12-months of deploying this model.\n",
    "    * The payers Senior Director, Sales & Marketing will determine the profitable growth and development of increasing patient population through marketing programs around this project. \n",
    "    * The hospital VP, Quality Improvement will determine the value of implementing this Data Science project as a clinical program designed to improve patient health outcome through promotion of preventive care services and management of chronic conditions. \n",
    "     * VP, IT Quality Assurance & Compliance will determine how well this model can be monitored and maintained once in production. \n",
    "    * The business has the aim of predicting the probability that each person has a diagnosis of Type 2 Dieabetes Mellitus which will be evaluated using the log loss metric.\n",
    "\n",
    "$$ log loss = \\frac{1}{n}\\sum_{i=1}^{N}y_{i}log(\\hat{y}_{i})+(1-y_{i})log(1-\\hat{y}_{i}) $$\n",
    "\n",
    "Where:\n",
    "$$N$$  is the number of patients \n",
    "$$log$$ is the natural logarithm\n",
    "$$\\hat{y}_{i}$$ is the posterior probability that the ith patient has diabetes\n",
    "$$y_{i}$$ is the ground truth ($$y_{i}=1$$ means the patient has diabetes, $$y_{i}=0$$ means that the patient does not).\n",
    "\n",
    "######Assess Situation\n",
    "1. Inventory of resources\n",
    "    * Personnel Sources:\n",
    "        * Identified project sponsor: Chief Medical Officer\n",
    "        * Identified technology personnel (all available over the next 60-days as needed):\n",
    "            * Chief Technology Officer\n",
    "            * Senior Data Architect\n",
    "        * Identified support personnel (all available over the next 60-days as needed):\n",
    "            * Business analyst\n",
    "            * Data Scientist\n",
    "            * Statisticians\n",
    "            * Medical Coding Expert\n",
    "            * Clinician\n",
    "            * Project Manager\n",
    "    * Sources of Data and Knowledge: \n",
    "        * Identified data sources:\n",
    "            * Electronic Health Records (EHR) which includes information on diagnoses, lab results, medications, allergies, immunizations, vital signs, and health behaviour. \n",
    "        * Identified types of data sources:\n",
    "            * 15 types of EHR as an extract\n",
    "        * Identified knowledge sources:\n",
    "            * http://www.PubMed.com\n",
    "            * Clinicians\n",
    "            * Analysts\n",
    "            * Data Scientist\n",
    "            * Data Architect\n",
    "            * Current model\n",
    "        * Identified types of knowledge sources:\n",
    "            * Online sources\n",
    "            * Written documentation\n",
    "            * Experts\n",
    "        * Describe the relevant background knowledge: \n",
    "            * One of the two major types of diabetes, the type in which the beta cells of the pancreas produce insulin but the body is unable to use it effectively because the cells of the body are resistant to the action of insulin. Although this type of diabetes may not carry the same risk of death from ketoacidosis, it otherwise involves many of the same risks of complications as does type 1 diabetes (in which there is a lack of insulin).\n",
    "\n",
    "            * The aim of treatment is to normalize the blood glucose in an attempt to prevent or minimize complications. People with type 2 diabetes may experience marked hyperglycaemia, but many do not require insulin injections and can be treated with diet, exercise, and oral hypoglycemic agents (drugs taken by mouth to lower the blood sugar).\n",
    "\n",
    "            * Type 2 diabetes requires good dietary control including the restriction of calories, lowered consumption of simple carbohydrates and fat with increased consumption of complex carbohydrates and fiber. Regular aerobic exercise is also an important method for treating both type 2 diabetes since it decreases insulin resistance and helps burn excessive glucose. Regular exercise also may help lower blood lipids and reduce some effects of stress, both important factors in treating diabetes and preventing complications.\n",
    "\n",
    "            * Type 2 diabetes is also known as insulin-resistant diabetes, non-insulin dependent diabetes, and adult-onset diabetes.\n",
    "        \n",
    "    * Computing Resources:\n",
    "        * Hardware platforms\n",
    "            * Amazon EC2 Instance:C4 instance which offer a compute-optimized instance, featuring the highest performing processors and the lowest price/compute performance in EC2. \n",
    "\n",
    "Model|vCPU|Mem (GB) |Storage| Dedicated EBS Throughput (Mbps) \n",
    "-|-|-|-\n",
    "    c4.4xlarge|16|30|EBS-Only|2,000\n",
    "    \n",
    "        * Software: \n",
    "            * R\n",
    "            * Python\n",
    "            * Jupyter\n",
    "        \n",
    "2. Requirements, assumptions & constraints\n",
    "    * Verify Constraints\n",
    "\n",
    "Constraint |Result\n",
    "-|-\n",
    "    All usernames/passwords tested for data access?| YES\n",
    "    Verified all legal constraints on data usage? | YES\n",
    "    Financial constraints covered in the project budget?| YES\n",
    "\n",
    "\n",
    "Task|Duration|Running Total\n",
    "-|-|-|-\n",
    "    Describe Data | 10 Days | 10 Days\n",
    "    Explore Data | 15 Days | 25 Days\n",
    "    Inferential Statistics | 10 Days | 35 Days\n",
    "    Modelling | 20 Days | 55 Days\n",
    "    Write-Up | 5 Days| 60 Days\n",
    "    \n",
    "    * Comprehensibility and quality of results\n",
    "    * Security\n",
    "    * Legal issues\n",
    "    * Assumptions\n",
    "    * Constraints\n",
    "3. Risks and Contingencies\n",
    "    * Risks: not being able to get the data, experts, or technology needed\n",
    "    * Contingency plan: \n",
    "        * If live data is not available, we will move forward with data extract only.\n",
    "        * If clinicians are not available to help with domain expertise because of competing priorities the data science team will pull together cursory research on relevant topics to gain intuition about the domain.\n",
    "        * If EC2 instance usage is exceeded we will migrate to workstations to continue solution development. \n",
    "4. Terminology\n",
    "    * Relevant Business Terminology:\n",
    "        * **ICD9** - The International Classification of Diseases, Ninth Revision.\n",
    "        * **Diabetes Mellitus** - is a chronic, lifelong condition that affects your body's ability to use the energy found in food. \n",
    "        * **Type II** - Begins with insulin resistance, a condition in which cells fail to respond to insulin properly. As the disease progresses a lack of insulin may also develop. \n",
    "    * Relevant Data Science Terminology:\n",
    "        * **Log Loss** - this is the loss function used in (multinomial) logistic regression and extensions of it such as neural networks, defined as the negative log-likelihood of the true label given a probabilistic classifier's predictions. \n",
    "        * **GBM** - (Gradient Boosted Machines) is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees.\n",
    "        * **RF** - (Random Forest) the combination of bagging, subspace sampling, and decision trees.\n",
    "5. Costs and Benefits\n",
    "    * Cost of the project: This project will cost \\$600,000 for the first 90-days and then $15,000 month for maintenance of the model.\n",
    "    * Potential benefits if successful: The hospital will been seen as a leader innovation by using data science to extend what the physicians are already doing. \n",
    "\n",
    "######Determine Data Science Goals\n",
    "1. Data science goals\n",
    "    * To build a model that takes in de-identified data of patients electronic health records and determine which patients have a diabetes diagnosis, as defined by ICD9 codes 250.**.\n",
    "2. Data science success criteria\n",
    "    * Predictive Accuracy: logloss less than 0.40\n",
    "    \n",
    "######Produce Project Plan\n",
    "Describe the intended plan for achieving the data science goals and thereby the business goals. Specify the steps to be performed during the rest of the project, including the initial selection of tools and techniques.\n",
    "1. Project plan\n",
    "\n",
    "Stage|Duration |Resource Required | Inputs | Outputs| Dependencies\n",
    "-|-|-|-|-\n",
    "    Describe Data | 10 Days | Data Scientist | SQL Tables from EMR | Summary Statistics; Visualizations | Data Architect\n",
    "    Exploratory Data Analysis |15 Days | Data Scientist, Clinician| Data | Outliers; Visualizations | Data Description\n",
    "    Inferential Statistics | 10 Days | Data Scientist, Clinician|Data |Imputation of Values|Clean Data Set\n",
    "    Feature Engineering |1 Day| Data Scientist| Data| Enhanced Features| Inferential Statistics\n",
    "    Feature Selection| 1 Day| Data Scientist| Data | Important Features | Feature Engineering\n",
    "    Model Training | 15 Days|Data| Highest Accuracy Models | Feature Selection\n",
    "    Evaluation| 4 Days | Models| Identify Successful Models | Model Training\n",
    "    Ensemble | 4 Days | Evaluation; Models| Stable Model| Evaluation\n",
    "    \n",
    "    \n",
    "2. Initial assessment of tools and techniques\n",
    "    * Data Science Tool Selected:\n",
    "        * R for descriptive statistics and exploratory analysis\n",
    "        * R for model development\n",
    "        * Jupyter for presentation of findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************************\n",
    "#Excercise 2\n",
    "\n",
    "Choose between A and B.\n",
    "***************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scientist A\n",
    "\n",
    "#PHASE II: Data Understanding\n",
    "\n",
    "######Collect Initial Data\n",
    "\n",
    "1. Initial data collection report\n",
    "\n",
    "**Allergy**\n",
    "This table contains a list of allergies recorded for a patient.\n",
    "\n",
    "Key|Column Name|Data Type | Description\n",
    "-|-|-|-\n",
    "    PK|AllergyGuid|UNIQUEIDENTIFIER NOT NULL| Unique identifier for the patient allergy record.\n",
    "    FK|PatientGuid|UNIQUEIDENTIFIER|Identifier for the patient.\n",
    "     |AllergyType|NVARCHAR(100) NOT NULL| Substance to which the patient has shown allergy. Values: Animal Dander(Contact); Baker's Yeast; Dairy; Dust(Inhaled); Dust Mites (Contact); Egg; Insect Stings (Contact); Latex(Contact); Medication; Melons, Bananas, Cucumbers (Rag-weed Pollen); Mold (inhaled); Nickel (Contact); Other nuts; Peanut; Pollen (inhaled); Seafood; Shellfish; Soy: Wheat\n",
    "      |Startyear|SMALLINT NOT NULL| Year of onset for the allergy.\n",
    "      |ReactionName|NVARCHAR(100) NULL|Allergic reaction reported by the patient. Values: Bloating/gas; Bradycardia; Chest Pain;Conjunctivitis; Cough; Diarrhea; Difficulty speaking or swallowing; Dizziness/Light headedness; Facial swelling; Hives; Irregular Heartbeat; Itchiness; Loss of consciousness; Nausea; Pain/cramping; Patchy swelling skin; Rash - generalized; Rash - localized; Respiratory Distress; Runny nose; Shortness of breath; Tachycardia; Tongue swelling; Vomiting; Wheezing\n",
    "      |Severityname|NVARCHAR(100) NULL| Severity of the patient allergy. Values: Very Mild; Mild; Modest; Severe.\n",
    "      |MedicationNdcCode|NVARCHAR(50) NULL|National Drug Code (NDC) identifier for medication taken by the patient for the allergy.\n",
    "      |UserGuid|UNIQUEIDENTIFIER NOT NULL| Identifier for the provider who recorded the allergy.\n",
    "\n",
    "\n",
    "**Condition**\n",
    "Reference table containing valid patient conditions.\n",
    "\n",
    "Key|Column Name|Data Type | Description\n",
    "-|-|-|-\n",
    "    PK|ConditionGuid|UNIQUEIDENTIFIER NOT NULL|Unique identifier for a condition.\n",
    "    |Code|NVARCHAR(50)NOT NULL| Code for the condition.\n",
    "    |Name|NVARCHAR(100) NOT NULL| Description of the condition.\n",
    "\n",
    "**Diagnosis**\n",
    "This table contains a list of diagnoses for a patient. \n",
    "\n",
    "Key|Column Name|Data Type | Description\n",
    "-|-|-|-\n",
    "    PK|DiagnosisGuid|UNIQUEIDENTIFIER NOT NULL|Unique identifier for a patient diagnosis.\n",
    "    FK|PatientGuid|UNIQUEIDENTIFIER NOT NULL|Identifier for the patient.\n",
    "    |ICD9Code|NVARCHAR(50) NOT NULL|ICD9 code for the diagnosis. (See http://en.wikipedia.org/wiki/List_of_ICD-9_codes)\n",
    "    |DiagnosisDescription|NVARCHAR(256) NOT NULL|Description of ICD9 code.\n",
    "    |StartYear|SMALLINT NULL|Year for the onset of the diagnosis.\n",
    "    |StopYear|SMALLINT NULL|Year for the end of the diagnosis.\n",
    "    |Acute|BIT NULL|Is the diagnosis an acute condition? If not acute, then the condition is considered chronic. Values: 1 = Acute; 0 = Chronic.\n",
    "|UserGuid|UNIQUEIDENTIFIER NOT NULL|Unique identifier for the provider who recorded the diagnosis.\n",
    "\n",
    "**Immunization**\n",
    "This table contains a list of immunizations for a patient. \n",
    "\n",
    "Key|Column Name|Data Type | Description\n",
    "-|-|-|-\n",
    "PK|ImmunizationGuid|UNIQUEIDENTIFIER NOT NULL|Unique identifier for the patient immunization record.\n",
    "FK|PatientGuid|UNIQUEIDENTIFIER NOT NULL|Identifier for the patient.\n",
    "|VaccineName|NVARCHAR(256) NULL|Name of the vaccine administered to the patient.\n",
    "|AdministeredYear|SMALLINT NULL|Year the vaccine was administered.\n",
    "|CvxCode|NVARCHAR(100) NULL|CVX code for the administered vaccine (CDC).\n",
    "|UserGuid|UNIQUEIDENTIFIER NOT NULL|Identifier for the provider who recorded the immunization.\n",
    "\n",
    "**LabObservation**\n",
    "This table contains lab test observations for a lab panel.\n",
    "\n",
    "Key|Column Name|Data Type | Description\n",
    "-|-|-|-\n",
    "    PK|LabObservationGuid|UNIQUEIDENTIFIER NOT NULL|Unique identifier for the lab test observation.\n",
    "    FK|LabPanelGuid|UNIQUEIDENTIFIER NULL|Identifier for the lab test panel.\n",
    "    |HL7Identifier|NVARCHAR(255) NOT NULL|Code for the lab test observation, as provided by the lab facility.\n",
    "    |HL7Text|NVARCHAR(255) NOT NULL|Name of the lab test observation, as provided by the lab facility.\n",
    "    |HL7CodingSystem|NVARCHAR(255) NOT NULL|Observation coding system used for the lab test observation code in column HL7Identifier.Values: LN = LOINC.\n",
    "    |IsLoinc|BIT NOT NULL|[Not used]\n",
    "    |ObservationValue|NVARCHAR(255) NOT NULL|Value for the lab test observation.\n",
    "    |IsValidValue|BIT NOT NULL|[Not used]\n",
    "    |Units|NVARCHAR(255) NULL|Units of measure for the lab test observation value.\n",
    "    |ReferenceRange|NVARCHAR(255) NULL|Range for normal lab test observation value.\n",
    "    |AbnormalFlags|NVARCHAR(255) NULL|Flags for abnormal lab test observation value. Values: Abnormal Result; Abnormal; Above Normal High; Alert High; Alert Low; Below Normal Low; Panic High; Panic Low; UKNOWN.\n",
    "    |ResultStatus|NVARCHAR(255) NULL|Status of the lab test observation.     Values: Corrected; Final; Incomplete; Not Performed; Preliminary; UKNOWN; UNKNOWN.\n",
    "    |ObservationYear|SMALLINT NULL|Year the lab test observation was performed.\n",
    "    |ObservationMethod|NVARCHAR(255) NULL|[Not used]\n",
    "    |UserGuid|UNIQUEIDENTIFIER NULL|Identifier for the provider for the lab test result.\n",
    "    |IsAbnormalValue|BIT NULL|Indicator whether the lab test observation is abnormal.\n",
    "    |Sequence|INT NULL|Sequence of the lab test observation for the lab test     panel.\n",
    "\n",
    "\n",
    "\n",
    "**LabPanel**\n",
    "This table contains lab test panels reported in a patient lab test result.\n",
    "\n",
    "Key|Column Name|Data Type | Description\n",
    "-|-|-|-\n",
    "    PK|LabPanelGuid|UNIQUEIDENTIFIER NOT NULL|Unique identifier for the lab test panel performed.\n",
    "    FK|LabResultGuid|UNIQUEIDENTIFIER NOT NULL|Identifier for the lab test result. \n",
    "    |PanelName|NVARCHAR(255) NULL|Name of the lab test panel.\n",
    "    |ObservationYear|SMALLINT NULL|Year the lab test panel was performed.\n",
    "    |DangerCode|NVARCHAR(255) NULL|[Not used]\n",
    "    |Status|NVARCHAR(255) NULL|Status of the lab test panel. Values: Cancelled; Corrected; Final; Incomplete; Not Performed; Preliminary; UKNOWN; UNKNOWN.\n",
    "    |Sequence|INT NULL|Sequence of the lab test panel within the lab test result.\n",
    "\n",
    "**LabResult**\n",
    "This table contains patient lab test results received from a lab facility.\n",
    "\n",
    "Key|Column Name|Data Type | Description\n",
    "-|-|-|-\n",
    "    PK|LabResultGuid|UNIQUEIDENTIFIER NOT NULL|Unique identifier for the lab test result.\n",
    "    |UserGuid|UNIQUEIDENTIFIER NULL|Identifier for the provider who ordered the lab test.\n",
    "    FK|PatientGuid|UNIQUEIDENTIFIER NULL|Identifier for the patient.\n",
    "    FK|TranscriptGuid|UNIQUEIDENTIFIER NULL|Patient visit transcript for the lab test order.\n",
    "    |PracticeGuid|UNIQUEIDENTIFIER NULL|Identifier for the provider's medical practice.\n",
    "    |FacilityGuid|UNIQUEIDENTIFIER NULL|Identifier for the facility performing the lab test.\n",
    "    |ReportYear|SMALLINT NULL| Year the lab result was created.\n",
    "    FK|AncestorLabResultGuid|UNIQUEIDENTIFIER NULL|Prior lab test result to which this result is related.\n",
    "\n",
    "**Medication**\n",
    "This table contains the medication history for a patient.\n",
    "\n",
    "Key|Column Name|Data Type | Description\n",
    "-|-|-|-\n",
    "    PK|MedicationGuid|UNIQUEIDENTIFIER NOT NULL|Unique identifier for a patient medication.\n",
    "    FK|PatientGuid|UNIQUEIDENTIFIER NOT NULL|Identifier for the patient taking the medication.\n",
    "    |NdcCode|NVARCHAR(50) NULL|NDC code for the medication. (See http://www.fda.gov/drugs/informationondrugs/ucm142438.htm)\n",
    "    |MedicationName|NVARCHAR(256) NULL|Name of the medication.\n",
    "    |MedicationStrength|NVARCHAR(50) NULL|Strength of the medication.\n",
    "    |Schedule|NVARCHAR(50) NULL|Controlled substance schedule. (See http://www.deadiversion.usdoj.gov/schedules/index.html)\n",
    "    FK|DiagnosisGuid|UNIQUEIDENTIFIER NULL|Identifier for the diagnosis that the provider linked to the medication.\n",
    "    |UserGuid|UNIQUEIDENTIFIER NOT NULL|Identifier of the provider who added the medication.\n",
    "\n",
    "**Patient**\n",
    "This table contains a header record for each patient.\n",
    "\n",
    "Key|Column Name|Data Type | Description\n",
    "-|-|-|-\n",
    "    PK|PatientGuid|UNIQUEIDENTIFIER NOT NULL|Unique identifier for a patient record.\n",
    "    |Gender|NVARCHAR(1) NOT NULL|Patient gender. Values: M = Male; F = Female.\n",
    "    |YearOfBirth| SMALLINT NOT NULL|Patient's year of birth.\n",
    "    |State| NVARCHAR(2) NOT NULL| State abbreviation for the state in which the patient lives.\n",
    "    |PracticeGuid |UNIQUEIDENTIFIER NOT NULL| Identifier for the practice whose providers are seeing the patient. \n",
    "\n",
    "**PatientCondition**\n",
    "This table lists conditions for a patient. \n",
    "\n",
    "Key|Column Name|Data Type | Description\n",
    "-|-|-|-\n",
    "    PK|PatientConditionGuid|UNIQUEIDENTIFIER NOT NULL|Unique identifier for a patient condition record.\n",
    "    FK|PatientGuid|UNIQUEIDENTIFIER NULL|Identifier for the patient with the condition.\n",
    "    FK|ConditionGuid|UNIQUEIDENTIFIER NULL|Identifier of the condition.\n",
    "    |CreatedYear|SMALLINT NOT NULL|Year the provider added the condition to the electronic health record.\n",
    "\n",
    "**PatientSmokingStatus**\n",
    "This table contains changes in smoking status for each patient,by year. \n",
    "\n",
    "Key|Column Name|Data Type | Description\n",
    "-|-|-|-\n",
    "PK| PatientSmokingStatusGuid| UNIQUEIDENTIFIER NOT NULL| Unique identifier for the patient smoking status record.\n",
    "FK| PatientGuid| UNIQUEIDENTIFIER NULL| Identifier for the patient.\n",
    "FK| SmokingStatusGuid| UNIQUEIDENTIFIER NULL| Identifier for the smoking status.\n",
    "|EffectiveYear| SMALLINT NULL| Starting year for the smoking status change.\n",
    "\n",
    "**Prescription**\n",
    "This table contains prescription records for a patient. A prescription is a written direction from the provider for administering medication.\n",
    "\n",
    "Key|Column Name|Data Type | Description\n",
    "-|-|-|-\n",
    "    PK| PrescriptionGuid| UNIQUEIDENTIFIER NOT NULL| Unique identifier for a prescription.\n",
    "    FK| PatientGuid| UNIQUEIDENTIFIER NOT NULL| Identifier for the patient.\n",
    "    FK| MedicationGuid| UNIQUEIDENTIFIER NULL| Identifier for the medication that the doctor prescribed.\n",
    "    |PrescriptionYear| SMALLINT NULL| Year in which the prescription was made.\n",
    "    |Quantity| NVARCHAR(50) NOT NULL| Number of units of the medication prescribed.\n",
    "    |NumberOfRefills| NVARCHAR(50) NULL| Number of refills included in the prescription.\n",
    "    |RefillAsNeeded| BIT NULL| Can the patient refills as needed? Values: 1 = Yes, 0 = No.\n",
    "    |GenericAllowed| BIT NULL |Can a generic drug be substituted? Values: 1 = Yes, 0 = No.\n",
    "    |UserGuid| UNIQUEIDENTIFIER NOT NULL| Identifier of the provider who created the prescription.\n",
    "\n",
    "**SmokingStatus**\n",
    "Reference table containing valid values for patient smoking status.\n",
    "\n",
    "Key|Column Name|Data Type | Description\n",
    "-|-|-|-\n",
    "    PK|SmokingStatusGuid|UNIQUEIDENTIFIER NOT NULL|Unique identifier for the smoking status record.\n",
    "    |Description|NVARCHAR(255) NULL|Description of the smoking status.\n",
    "    |NISTcode|INT NULL|Corresponding NIST code value for smoking status, as specified in HHS HIT 45 CFR ยง170.302(g).\n",
    "    \n",
    "**Transcript**\n",
    "This table contains visit transcript records for a patient. Each patient visit is documented by a visit transcript record. \n",
    "\n",
    "Key|Column Name|Data Type | Description\n",
    "-|-|-|-\n",
    "    PK|TranscriptGuid| UNIQUEIDENTIFIER NOT NULL| Unique identifier for a visit transcript.\n",
    "    FK| PatientGuid| UNIQUEIDENTIFIER NOT NULL| Identifier for the patient.\n",
    "    |VisitYear| SMALLINT NOT NULL| Year of the visit for which the transcript was created.\n",
    "    |Height| FLOAT NULL| Patient height (inches).\n",
    "    |Weight| FLOAT NULL| Patient weight (lbs).\n",
    "    |BMI| FLOAT NULL| Body mass index.\n",
    "    |SystolicBP| SMALLINT NULL| Systolic blood pressure.\n",
    "    |DiastolicBP| SMALLINT NULL| Diastolic blood pressure.\n",
    "    |RespiratoryRate| SMALLINT NULL| Respiratory rate (breaths per minute).\n",
    "    |HeartRate| SMALLINT NULL| Heart rate (beats per minute).\n",
    "    |Temperature| FLOAT NULL| Temperature as entered by the provider (Expected as degrees Fahrenheit; a very small subset in Centigrade).\n",
    "    |PhysicianSpecialty| NVARCHAR(256) NOT NULL| Speciality of the provider seeing the patient.\n",
    "    |UserGuid| UNIQUEIDENTIFIER NOT NULL| Identifier of the provider recording the visit transcript.\n",
    "\n",
    "**TranscriptAllergy**\n",
    "This table contains a list of allergies recorded per visit transcript.\n",
    "\n",
    "Key|Column Name|Data Type | Description\n",
    "-|-|-|-\n",
    "    PK|TranscriptAllergyGuid| UNIQUEIDENTIFIER NOT NULL| Unique identifier for the visit transcript allergy record.\n",
    "    FK| TranscriptGuid| UNIQUEIDENTIFIER NOT NULL| Identifier for the visit transcript.\n",
    "    FK| AllergyGuid| UNIQUEIDENTIFIER NOT NULL| Identifier for the allergy assigned to the visit transcript.\n",
    "    |DisplayOrder| INT NOT NULL| Sequence that the allergy appears in the visit transcript.\n",
    "\n",
    "**TranscriptDiagnosis**\n",
    "This table contains a list of diagnoses per visit transcript.\n",
    "\n",
    "Key|Column Name|Data Type | Description\n",
    "-|-|-|-\n",
    "    PK| TranscriptDiagnosisGuid| UNIQUEIDENTIFIER NOT NULL| Unique identifier for a visit transcript diagnosis record.\n",
    "    FK| TranscriptGuid| UNIQUEIDENTIFIER NULL| Identifier for the visit transcript.\n",
    "    FK| DiagnosisGuid| UNIQUEIDENTIFIER NOT NULL| Identifier for the diagnosis assigned to the visit transcript.\n",
    "    |OrderBy| INT NOT NULL| Sequence that the diagnosis appears in the visit transcript. Sometimes indicates the severity or importance of the diagnosis in relation to other diagnoses in the same visit transcript.\n",
    "\n",
    "\n",
    "\n",
    "######Describe Data\n",
    "Examine the surface properties of the acquired data.\n",
    "\n",
    "1. Data description analysis\n",
    "    * Summary statistics on data\n",
    "    * Format of the data\n",
    "    * Quantity of the data (number of records and fields)\n",
    "    * Identities of the fields\n",
    "    * Evaluate whether data acquired satisfied the relevant requirements\n",
    "\n",
    "######Explore Data\n",
    "1. Data exploration report\n",
    "    * First findings or initial hypothesis\n",
    "    * Impact on the remainder of the project\n",
    "    * What graphs and plots to indicate data characteristics that suggest further examination of interesting data subsets\n",
    "\n",
    "######Verify Data Quality\n",
    "1. Data quality report\n",
    "    * Address questions: \n",
    "        * Is the data complete?\n",
    "        * Is it correct, or does it contain errors, if so how common are they?\n",
    "        * Are there missing values in the data? If so, how are they represented, where do they occur, and how common are they?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**===================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scientist B\n",
    "\n",
    "#PHASE II: Data Understanding\n",
    "\n",
    "######Collect Initial Data\n",
    "\n",
    "1. Initial data collection report\n",
    "\n",
    "Table|Description\n",
    "-|-\n",
    "    **Allergy**|This table contains a list of allergies recorded for a patient.\n",
    "    **Condition**| Reference table containing valid patient conditions.\n",
    "    **Diagnosis** | This table contains a list of diagnoses for a patient. \n",
    "    **Immunization **| This table contains a list of immunizations for a patient. \n",
    "    **LabObservation**|This table contains lab test observations for a lab panel.\n",
    "    **LabPanel**| This table contains lab test panels reported in a patient lab test result.\n",
    "    **LabResult**|This table contains patient lab test results received from a lab facility.\n",
    "    **Medication**| This table contains the medication history for a patient.\n",
    "    **Patient**|This table contains a header record for each patient.\n",
    "    **PatientCondition**|This table lists conditions for a patient. \n",
    "    **PatientSmokingStatus**|This table contains changes in smoking status for each patient,by year. \n",
    "    **Prescription**|This table contains prescription records for a patient. A prescription is a written direction from the provider for administering medication.\n",
    "    **SmokingStatus**| Reference table containing valid values for patient smoking status.\n",
    "    **Transcript**|This table contains visit transcript records for a patient. Each patient visit is documented by a visit transcript record. \n",
    "    **TranscriptAllergy**| This table contains a list of allergies recorded per visit transcript.\n",
    "    **TranscriptDiagnosis**| This table contains a list of diagnoses per visit transcript.\n",
    "\n",
    "######Describe Data\n",
    "Examine the surface properties of the acquired data.\n",
    "\n",
    "1. Data description analysis\n",
    "    * Below are summary statistics on the patient data:\n",
    "\n",
    "**Data Quality Output**\n",
    "\n",
    "(a) Continuous Features\n",
    "\n",
    "Feature|Count|% Miss. |Card.|Min.|1st Qrt.|Mean|Median|3rd. Qrt.|Max|Std. Dev.\n",
    "-|-|-|-|\n",
    "    RangeSystolicBP|14,926|0%|171|0.00|4.00|12.46|11.00|20.00|94.00|10.6657\n",
    "    RangeDiastolicBP|14,926|0%|493|0.00|2.00|8.25|8.00|12.00|52.00|6.903738\n",
    "    HighLowBP|14,926|0%|78|0.00|41.00|49.08|48.00|55.00|125.00|10.99835\n",
    "    RespiratoryRateMaxT|14,926|2.0%|36|0.00|0.00|12.27|16.00|18.00|80.00|8.244918\n",
    "    RespiratoryRateMedian|14,926|0.0%|28|0.00|0.00|11.81|16.00|18.00|79.00|7.909366\n",
    "    RangeBMI|14,926|0.0%|40|0.00|0.00|0.9779|0.6359|1.3643|14.4170|1.219054\n",
    "\n",
    "\n",
    "(b) Categorical Features\n",
    "\n",
    "Feature|Count|% Miss. |Card.|Mode|Mode Freq.|Mode %|2nd Mode|2nd Mode Freq.|2nd Mode %\n",
    "-|-|-|-|-|-|-|-|-|-   \n",
    "    Gender|14,926|0%|2|F|8,554|57.3%|M|6,372|42.7%\n",
    "    PracticeGuid|14,926|0%|28|4D27688B-C925-4513-9CF9-8D281ACC6712|867|5.8%|5639C194-706D-49FE-AF69-D4F36752893C|740|5.0%\n",
    "    \n",
    "\n",
    "\n",
    "######Explore Data\n",
    "1. Data exploration report\n",
    "   Initial findings suggests that we should eliminate a few Patient records, as they will have an impact on the remainder of the project. \n",
    "\n",
    "*Underweight Valid Patients(valid weight <85)*\n",
    "\n",
    "Category: Underweight | PatientGuid\n",
    "-|-\n",
    "    |'3C8D1326-7D79-4350-89D8-1271A34C62E3'\n",
    "    |'3066A99F-3B26-44A3-95C3-349FCCEB303B'\n",
    "    |'3E917FBC-C42E-4948-A834-EA999131D1A0'\n",
    "    |'812E6BE3-BDBB-4FD2-AA86-7E4FCEA33431'\n",
    "    |'8B6688AB-E183-4C32-8FE6-29B9D8865687'\n",
    "    |'A71E42F0-385F-4102-BE27-FB55ED06D3AE'\n",
    "    |'D70EDC3E-24D7-44E7-993A-501D620E999A'\n",
    "    |'D70EDC3E-24D7-44E7-993A-501D620E999A'\n",
    "    |'BB0CC274-240A-4C02-A764-5070CC514A87'\n",
    "    |'D0703010-9CF8-426C-BD1B-61E8C53D0338'\n",
    "    |'096AA3A2-3306-4F9A-9082-6B479C2BB5AA'\n",
    "    |'148B6713-1D0D-4DE4-8EE5-E6D7988088ED'\n",
    "    \n",
    "*Overweight valid patients (valid weight >320)*    \n",
    "\n",
    "Category: Overweight | PatientGuid\n",
    " -|-\n",
    "    |'04477471-FAFE-45AE-9EF8-6EC94B94789C'\n",
    "    |'0D3EF269-0675-444A-9F45-6FBCF2046CCD'\n",
    "    |'100ECEEB-8759-4D59-AC23-A86697DD4113'\n",
    "    |'10AA6386-B0A5-4F6B-B495-DBC588042E4D'\n",
    "    |'17DCFE68-7A86-473C-A589-11B0FC256BA2'\n",
    "    |'1B0556CF-72DF-480E-8429-DF61C252F16F'\n",
    "    |'25B9E447-F7E3-479C-8B72-E6D76CA3182D'\n",
    "    |'2A767E8A-1E47-4555-B11A-8A507B48DD64'\n",
    "    |'2C2F654C-FC57-4E06-9E41-9AEE559A7D6E'\n",
    "    |'2CC737E9-98B8-48FE-A744-F75770C59218'\n",
    "    |'2EDC74B4-360A-4114-AB6C-BF0689AF2C70'\n",
    "    |'3F8A2228-0DF3-4FAF-8C26-F04A9DD14C36'\n",
    "    |'50BABFE9-D522-425D-86A0-170300961A46'\n",
    "    |'53C120E7-11B2-40F2-AC09-DA209DFA2CBE'\n",
    "    |'5883AF5C-513F-4F2A-B204-762AAF6963E6'\n",
    "    |'61B927CE-1EB3-4464-B843-4BA4943BA027'\n",
    "    |'71047BE4-1639-4F34-8BE9-5AA89281F9C7'\n",
    "    |'763112F7-6F43-43D7-B745-75C0506E4197'\n",
    "    |'7CA6C507-CCA6-4CF2-880E-F11EBECAD928'\n",
    "    |'7E3B9F76-C55F-46B9-897D-E5C4DB645CF0'\n",
    "    |'83190041-69EC-4D8C-8486-DF5C99CB1844'\n",
    "    |'87F932AE-370E-49B8-8B77-EE866EB04267'\n",
    "    |'91A9EECB-093F-4DA7-9F18-4C803E5F94B4'\n",
    "    |'92626713-16CE-4473-8523-ADCDB86A7DC8'\n",
    "    |'A1E6ED8A-68AC-45F1-B622-28833D2ECC37'\n",
    "    |'A42807AE-854E-409B-83E0-6B2389E4DE44'\n",
    "    |'A53C6FBB-730C-4F4C-A128-6B5F3120BCE1'\n",
    "\n",
    "   \n",
    "The below graph indicates data characteristics that suggest further examination of interesting data subsets: \n",
    "\n",
    "<img src=\"http://i1377.photobucket.com/albums/ah57/drmingle1/Jupyter%20-%20Healthcare%20Data%20Science/PatientFeatures_zpslfdqqjtw.png\" alt=\"Matrix\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "######Data Quality\n",
    "The data is complete. It does contain an insignificant amount of errors and there are some missing values as well, however they do not occur that often. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************************\n",
    "#Exercise 3\n",
    "\n",
    "Choose between A and B.\n",
    "***************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scientist A\n",
    "\n",
    "#PHASE III: Data Preparation\n",
    "\n",
    "######Select Data\n",
    "Our aim is to decide on the data to be used for analysis. Criteria for this include relevance to the data science goals, quality, and technical constraints such as limits on data volume or data types. \n",
    "\n",
    "1. Rationales for inclusion/exclusion\n",
    "    * List the data to be included and the reasons:\n",
    "    * List the data to be excluded and the reason:\n",
    "\n",
    "######Clean Data\n",
    "Raise the data quality to the level required by the selected analysis techniques.\n",
    "\n",
    "1. Data cleaning report\n",
    "    * Describe what decision and actions were taken to address the data quality problems reported during the Verify Data Quality and Data Understanding phase:\n",
    "    * Transformations of the data for cleaning purposes and the possible impact on the analysis should be considered.\n",
    "\n",
    "######Construct Data\n",
    "This task includes constructive data preparation operations such as the product of derived attributes or entire new records or transformed values for existing attributes.\n",
    "\n",
    "1. Derived attributes\n",
    "    * New attributes that are constructed from one or more existing attributes:\n",
    "2. Generated records\n",
    "    * Describe the creation of completely new records:\n",
    "\n",
    "######Integrate Data\n",
    "Methods whereby information is combined from multiple tables or records to create new records or values\n",
    "\n",
    "1. Merged data\n",
    "    * Joining together various tables:\n",
    "    * Aggregations:\n",
    "\n",
    "######Format Data\n",
    "Formatting transformations refer to the syntactic modifications made to the data that do not change the meaning, but might be required by the modeling tool.\n",
    "\n",
    "1. Reformatted data\n",
    "    * What was required to appropriately take into the model:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**===================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scientist B\n",
    "\n",
    "#PHASE III: Data Preparation\n",
    "\n",
    "######Select Data\n",
    "Our aim is to decide on the data to be used for analysis. Criteria for this include relevance to the data science goals, quality, and technical constraints such as limits on data volume or data types. \n",
    "\n",
    "We included data records that seem to appear normal to our teams subject matter experts. In addition, any other data records which appeared abnormal were exluded from the training dataset. \n",
    "\n",
    "\n",
    "######Clean Data\n",
    "We aimed to raise the data quality to the level required by our selected analysis techniques.\n",
    "\n",
    "We addressed typos and outliers to improve data quality problems which we encountered during hte verify data quality and data understanding phase. We spent considerable amount of time in cleaning transcript measures. \n",
    "\n",
    "\n",
    "######Construct Data\n",
    "Below are features which have been derived attributes: \n",
    "\n",
    "2. Height median was calculated\n",
    "3. BMI was recalculated with this constant height for each patient, eliminating any noise of measures fluctuations.\n",
    "4. For weight, height, BMI, systolic blood pressure, diastolic blood pressure, temperature, respiratory rate were calculated median and truncated maximum and minimum.\n",
    "5. For 2012 and 2009 years, not complete, a weight was used for calculate features with ratios.\n",
    "9. Other features were created for missing data: medication without prescriptions, diagnoses without transcripts, patients without lab observation. \n",
    "9. Some families treated were ACEI (Angiotensin Converting Enzyme Inhibitor), AIIRA (Angiotensin II Receptor Antagnosists), antifungals, benzodiazepines, beta blockers, fibrates, glucocorticoids, L type Calcium channel blockers, statins, thiazides, antillipemic or loop diuretics.\n",
    "9. For states wiht more than 450 patients a binary feature was used.\n",
    "9. 'Smoking Status' and 'Previous Smoking Situation' were created. Other possible features like allergy or immunization don't take account due low number of patients.\n",
    "\n",
    "We did not generate any new records for this data. \n",
    "\n",
    "######Integrate Data\n",
    "We have merged together data using ~1,800 lines of code in the *FeatureCreation.R* file various methods to create new values for each patient record:\n",
    "\n",
    "New Values Created|Features Generated\n",
    "-|-\n",
    "    |Smoker\n",
    "    |L2_AbdominalHernia\n",
    "    |L2_AbdominalPain\n",
    "    |L2_AbuseMonotoring\n",
    "    |L2_Acne\n",
    "    |L2_AcuteBronchitis\n",
    "    |L2_AcuteCystitis\n",
    "    |L2_Alcohol\n",
    "    |L2_Allergy\n",
    "    |L2_AMI\n",
    "    |L2_AnginaPectoris\n",
    "    |L2_Anxiety\n",
    "    |L2_Arthropathy\n",
    "    |L2_Asthma\n",
    "    |L2_AtherosclerosisCoronary\n",
    "    |L2_AtherosclerosisPeripheral\n",
    "    |L2_BackPain\n",
    "    |L2_Bladder\n",
    "    |L2_BlindDeficiency\n",
    "    |L2_BloodAnormal\n",
    "    |L2_BoneCartilage\n",
    "    |L2_BoneDeformity\n",
    "    |L2_Calculus\n",
    "    |L2_Candida\n",
    "    |L2_CaProstate\n",
    "    |L2_CardiacInsufficiency\n",
    "    |L2_CardiacOther\n",
    "    |L2_CardiacValve\n",
    "    |L2_CarpalSyndrome\n",
    "    |L2_CaSkin\n",
    "    |L2_Cataract\n",
    "    |L2_Cellulitis\n",
    "    |L2_CerebralDegeneration\n",
    "    |L2_CerebroVascular\n",
    "    |L2_Cerumen\n",
    "    |L2_Cervical\n",
    "    |L2_ChestPain\n",
    "    |L2_ChronicCystitis\n",
    "    |L2_ChronicPainSynd\n",
    "    |L2_ChronicRenalFailure\n",
    "    |L2_Coagulation\n",
    "    |L2_ColitisNoninfectious\n",
    "    |L2_Conjunctivitis\n",
    "    |L2_Constipation\n",
    "    |L2_COPD\n",
    "    |L2_Corns\n",
    "    |L2_Cough\n",
    "    |L2_CRP\n",
    "    |L2_DeficiencyAnemia\n",
    "\n",
    "\n",
    "######Format Data\n",
    "We did not change the meaning of the data, but we did reformat many of the continuous values in the patient data.\n",
    "\n",
    "Reformatted data:\n",
    "We implemented normalization of the continuous features in the the Patient ABT that cover very different ranges since this is known to cause difficulty for some machine learning algorithms. We applied this technique so we can change the continuous feature to fall within a specified range while maintaining the relative differences between the values for the feature. \n",
    "\n",
    "$$a_{'}^{i}=\\frac{a_{i}-min(a)}{max(a)-min(a)} \\times(high-low)+low$$\n",
    "\n",
    "where $$a_{'}^{i}$$ is the normalized feature value\n",
    "    $$a_{i}$$ is the original value\n",
    "    $$min(a)$$ is the minimum value of feature *a*\n",
    "    $$max(a)$$ is the maximum value of feature *a*\n",
    "    $$low$$ and $$high$$ are the minimum and maximum values of the desired range\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************************\n",
    "#Exercise 4\n",
    "\n",
    "Choose between A and B.\n",
    "***************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Scientist A**\n",
    "\n",
    "#PHASE IV: Modeling\n",
    "\n",
    "######Select Modeling Technique\n",
    "\n",
    "1. Modeling technique\n",
    "We have used a combination of Gradient Boosting Machines (GBM) and Random Forest (RF). Each are information-based learners. As with all tree representations, a decision tree consists of a root node, interior nodes, and leaf nodes that are connected by branches. Each non-leaf node (root and interior) in the tree specifies a test to be carried out on a descriptive feature. The number of possible levels that a descriptive feature can take determines the number of downward branches from a non-leaf node. Each of the leaf nodes specifies a predicted level of the target feature. \n",
    "\n",
    "The process of using a decision tree to make a prediction for a query instance starts by testing the value of the descriptive feature at the root node of the tree. The result of this test determines which of the root node's children  the process should then descend to. These two steps of testing the value of a descriptive feature and descending a level in the tree are then repeated until the process comes to a leaf node at which a prediction can be made. \n",
    "\n",
    "Regarding Random Forest, this algorithm is an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random forests correct for decision trees' habit of overfitting to their training set.The algorithm for inducing a random forest was developed in order to construct a collection of decision trees with controlled variance.\n",
    "\n",
    "2. Modeling assumptions\n",
    "\n",
    "GBM aims to work against fitting the training set too closely and employs regularization to enhance the generalization of the model. One natural regularization parameter is the number of gradient boosting iterations. Increasing the number of trees reduces the error on the training set, but setting it too high may lead to overfitting. \n",
    "\n",
    "Regularization by shrinkage, empirically it has been found that using smal learning rates yields dramatic improvements in model's generalization ability over gradient boosting without shrinkage. However, it comes with higher computational costs. In addition, lower learning rates require more iterations. \n",
    "\n",
    "Subsampling is used to define an out-of-bag estimate of the prediction performance improvement by evaluating predictions on those observations which were not used in the building of the next base learner. Out-of-bag estimates help avoid the need for an independent validation dataset, but often underestimate actual performance improvement and the optimal number of iterations. \n",
    "\n",
    "Another useful regularization technique for gradient boosted trees is to penalize model complexity of the learned model. The model complexity can be defined proportional number of leaves in the learned trees. \n",
    "\n",
    "Concerning RF, Random forests differ in only one way from this general scheme: they use a modified tree learning algorithm that selects, at each candidate split in the learning process, a random subset of the features. This process is sometimes called \"feature bagging\". The reason for doing this is the correlation of the trees in an ordinary bootstrap sample: if one or a few features are very strong predictors for the response variable (target output), these features will be selected in many of the trees, causing them to become correlated.\n",
    "\n",
    "######Generate Test Design\n",
    "\n",
    "Regarding test design, we made use of a hold-out test set. This was created by randomly sampling a portion of the data in the ABT we created during the Data Preparation phase. It is important to not that this random sample is never used in the training process but reserved until all the model has been trained, when we would like to evaluate its performance. The performanc eof th emodel on the test set is a better measure of how the model is likely to perform when actually deployed and shows how well the model can generalize beyond the instances used to train it. We felt that the most important rule in evaluating models was not to use the same data sample both to evaluate the performance of a predictive model and to train it. \n",
    "\n",
    "\n",
    "######Build Model\n",
    "Below are the parameter settings and results for the various models:\n",
    "\n",
    "***Gradient Boosting Machine***\n",
    "\n",
    "GBM models were fitted with differing parameters. For cross-validation stopping the wrapper 'gbm.step' in dismo R package was used, only modified for add n.minobsinnode parameter.\n",
    "\n",
    "GBM Model | CV Error | Folds | Trees | Depth | Shrinkage | Bag Frac | Node Size | Tolerance\n",
    "-|-|-|-|-|-|-|-\n",
    "    gbm 10_5 0.003_0.80_30 | 0.31210 | 10|7,550| 5 | 0.003|0.80|30|0.001\n",
    "    gbm10_5_0.003_0.80_30_tolhalf_ext |\t0.31153|\t10|\t8,500|\t5|\t0.003|\t0.80|\t30|\t0.0005\n",
    "    gbm10_5_0.0025_0.80_30\t|0.31319\t|10\t|8,000|\t5|\t0.003|\t0.80|\t30|\t0.001\n",
    "    gbm10_5_0.0025_0.80_30_ext|\t0.31312\t|10|\t7,750|\t5|\t0.0025|\t0.80|\t30|\t0.001\n",
    "    gbm10_5_0.0025_0.80_30_tolhalf\t|0.31122\t|10\t|11,000|\t5|\t0.0025|\t0.80|\t30|\t0.0005\n",
    "    gbm10_5_0.0025_0.80_30_tolhalf_ext\t|0.31139|\t10\t|10,450|\t5|\t0.0025|\t0.80|\t30|\t0.0005\n",
    "    gbm20_5_0.002_0.80_10\t|0.31049\t|20|\t13,450|\t5\t|0.002|\t0.80|\t10|\t0.001\n",
    "    gbm20_5_0.002_0.80_15\t|0.31040\t|20\t|12,950\t|5\t|0.002\t|0.80\t|15\t|0.001\n",
    "    gbm20_5_0.0025_0.80_20\t|0.30878\t|20\t|12,300\t|5\t|0.0025\t|0.80\t|20\t|0.001\n",
    "    gbm20_5_0.0025_0.80_40\t|0.31040\t|20\t|10,500\t|5\t|0.0025\t|0.80\t|40\t|0.001\n",
    "    gbm20_6_0.002_0.80_30\t|0.30931\t|20\t|12,200\t|6\t|0.002\t|0.80\t|30\t|0.001\n",
    "\n",
    "    \n",
    "***Random Forest***\n",
    "Four models were fitted with Random Forest, all parameters by defect except the detailed in table.\n",
    "\n",
    "RF Model | OOB MSE | Trees | Node Size\n",
    "-|-|-|-\n",
    "    RF1 | 0.10055| 15,000 | 5\n",
    "    RF5\t|0.10076|\t30,000|\t15\n",
    "    RF2\t|0.10089|\t15,000|\t20\n",
    "    RF3\t|0.10102|\t15,000|\t40\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the actual modeling code produced: "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Model F\n",
    "set.seed(223646)\n",
    "gbm10_5_0.003_0.80_30<-gbm.step(Patient2,gbm.x=c(3:ncol(Patient2)),gbm.y=2,\n",
    "tree.complexity=5,\n",
    "n.folds=10,n.trees=50, learning.rate=0.003,bag.fraction=0.80,n.minobsinnode=30,tolerance = 0.001,\n",
    "family=\"bernoulli\",max.trees=30000,keep.fold.models = TRUE, keep.fold.vector = TRUE, keep.fold.fit=TRUE)\n",
    "save(gbm10_5_0.003_0.80_30,file=\"c://dmii/models/gbm10_5_0.003_0.80_30.RData\",compress=TRUE)\n",
    "pred<-predict.gbm(gbm10_5_0.003_0.80_30,Patient[Patient$dmIndicator==-1,dmii],n.trees=gbm10_5_0.003_0.80_30$gbm.call$best.trees,type=\"response\")\n",
    "sentdata<- cbind(as.character(Patient$PatientGuid[Patient$dmIndicator==-1]),as.numeric(pred)) \n",
    "colnames(sentdata)<-c('PatientGuid','dmIndicator')\n",
    "write.csv(sentdata, file=\"c://dmii/models/gbm10_5_0.003_0.80_30.csv\", row.names = FALSE) \n",
    "save(gbm10_5_0.003_0.80_30,file=\"c://dmii/models/gbm10_5_0.003_0.80_30.RData\",compress=TRUE)\n",
    "## cv fold predictions set for stacking models\n",
    "cvestim<-cbind(as.character(Patient2$PatientGuid),exp(gbm10_5_0.003_0.80_30$fold.fit)/(1+exp(gbm10_5_0.003_0.80_30$fold.fit)))\n",
    "colnames(cvestim)<-c('PatientGuid','gbm10_5_0.003_0.80_30')\n",
    "write.csv(cvestim,file=\"c://dmii/models/gbm10_5_0.003_0.80_30_cvest.csv\", row.names = FALSE)\n",
    "\n",
    "#  Model 5\n",
    "set.seed(223646)\n",
    "gbm20_5_0.002_0.80_10<-gbm.step(Patient2,gbm.x=c(3:ncol(Patient2)),gbm.y=2,\n",
    "tree.complexity=5,\n",
    "n.folds=20,n.trees=50, learning.rate=0.002,bag.fraction=0.80,n.minobsinnode=15,tolerance = 0.0005,\n",
    "family=\"bernoulli\",max.trees=30000,keep.fold.models = TRUE, keep.fold.vector = TRUE, keep.fold.fit=TRUE)\n",
    "save(gbm20_5_0.002_0.80_10,file=\"c://dmii/models/gbm20_5_0.002_0.80_10.RData\",compress=TRUE)\n",
    "pred<-predict.gbm(gbm20_5_0.002_0.80_10,Patient[Patient$dmIndicator==-1,dmii],n.trees=gbm20_5_0.002_0.80_10$gbm.call$best.trees,type=\"response\")\n",
    "sentdata<- cbind(as.character(Patient$PatientGuid[Patient$dmIndicator==-1]),as.numeric(pred)) \n",
    "colnames(sentdata)<-c('PatientGuid','dmIndicator')\n",
    "write.csv(sentdata, file=\"c://dmii/models/gbm20_5_0.002_0.80_10.csv\", row.names = FALSE) \n",
    "## cv fold predictions set for stacking models\n",
    "cvestim<-cbind(as.character(Patient2$PatientGuid),exp(gbm20_5_0.002_0.80_10$fold.fit)/(1+exp(gbm20_5_0.002_0.80_10$fold.fit)))\n",
    "colnames(cvestim)<-c('PatientGuid','gbm20_5_0.002_0.80_10')\n",
    "write.csv(cvestim,file=\"c://dmii/models/gbm20_5_0.002_0.80_10_cvest.csv\", row.names = FALSE)\n",
    "\n",
    "#  Model 4\n",
    "set.seed(223646)\n",
    "gbm20_5_0.002_0.80_15<-gbm.step(Patient2,gbm.x=c(3:ncol(Patient2)),gbm.y=2,\n",
    "tree.complexity=5,\n",
    "n.folds=20,n.trees=50, learning.rate=0.002,bag.fraction=0.80,n.minobsinnode=15,tolerance = 0.0005,\n",
    "family=\"bernoulli\",max.trees=30000,keep.fold.models = TRUE, keep.fold.vector = TRUE, keep.fold.fit=TRUE)\n",
    "save(gbm20_5_0.002_0.80_15,file=\"c://dmii/models/gbm20_5_0.002_0.80_15.RData\",compress=TRUE)\n",
    "pred<-predict.gbm(gbm20_5_0.002_0.80_15,Patient[Patient$dmIndicator==-1,dmii],n.trees=gbm20_5_0.002_0.80_15$gbm.call$best.trees,type=\"response\")\n",
    "sentdata<- cbind(as.character(Patient$PatientGuid[Patient$dmIndicator==-1]),as.numeric(pred)) \n",
    "colnames(sentdata)<-c('PatientGuid','dmIndicator')\n",
    "write.csv(sentdata, file=\"c://dmii/models/gbm20_5_0.002_0.80_15.csv\", row.names = FALSE) \n",
    "## cv fold predictions set for stacking models\n",
    "cvestim<-cbind(as.character(Patient2$PatientGuid),exp(gbm20_5_0.002_0.80_15$fold.fit)/(1+exp(gbm20_5_0.002_0.80_15$fold.fit)))\n",
    "colnames(cvestim)<-c('PatientGuid','gbm20_5_0.002_0.80_15')\n",
    "write.csv(cvestim,file=\"c://dmii/models/gbm20_5_0.002_0.80_15_cvest.csv\", row.names = FALSE)\n",
    "\n",
    "#  Model 3\n",
    "set.seed(223646)\n",
    "gbm20_6_0.002_0.80_30<-gbm.step(Patient2,gbm.x=c(3:ncol(Patient2)),gbm.y=2,\n",
    "tree.complexity=6,\n",
    "n.folds=20,n.trees=50, learning.rate=0.002,bag.fraction=0.80,n.minobsinnode=30,tolerance = 0.0005,\n",
    "family=\"bernoulli\",max.trees=30000,keep.fold.models = TRUE, keep.fold.vector = TRUE, keep.fold.fit=TRUE)\n",
    "save(gbm20_6_0.002_0.80_30,file=\"c://dmii/models/gbm20_6_0.002_0.80_30.RData\",compress=TRUE)\n",
    "pred<-predict.gbm(gbm20_6_0.002_0.80_30,Patient[Patient$dmIndicator==-1,dmii],n.trees=gbm20_6_0.002_0.80_30$gbm.call$best.trees,type=\"response\")\n",
    "sentdata<- cbind(as.character(Patient$PatientGuid[Patient$dmIndicator==-1]),as.numeric(pred)) \n",
    "colnames(sentdata)<-c('PatientGuid','dmIndicator')\n",
    "write.csv(sentdata, file=\"c://dmii/models/gbm20_6_0.002_0.80_30.csv\", row.names = FALSE) \n",
    "## cv fold predictions set for stacking models\n",
    "cvestim<-cbind(as.character(Patient2$PatientGuid),exp(gbm20_6_0.002_0.80_30$fold.fit)/(1+exp(gbm20_6_0.002_0.80_30$fold.fit)))\n",
    "colnames(cvestim)<-c('PatientGuid','gbm20_6_0.002_0.80_30')\n",
    "write.csv(cvestim,file=\"c://dmii/models/gbm20_6_0.002_0.80_30_cvest.csv\", row.names = FALSE)\n",
    "\n",
    "#  Model 2\n",
    "set.seed(223646)\n",
    "gbm20_5_0.0025_0.80_40<-gbm.step(Patient2,gbm.x=c(3:ncol(Patient2)),gbm.y=2,\n",
    "tree.complexity=5,\n",
    "n.folds=20,n.trees=50, learning.rate=0.0025,bag.fraction=0.80,n.minobsinnode=40,tolerance = 0.0005,\n",
    "family=\"bernoulli\",max.trees=30000,keep.fold.models = TRUE, keep.fold.vector = TRUE, keep.fold.fit=TRUE)\n",
    "save(gbm20_5_0.0025_0.80_40,file=\"c://dmii/models/gbm20_5_0.0025_0.80_40.RData\",compress=TRUE)\n",
    "pred<-predict.gbm(gbm20_5_0.0025_0.80_40,Patient[Patient$dmIndicator==-1,dmii],n.trees=gbm20_5_0.0025_0.80_40$gbm.call$best.trees,type=\"response\")\n",
    "sentdata<- cbind(as.character(Patient$PatientGuid[Patient$dmIndicator==-1]),as.numeric(pred)) \n",
    "colnames(sentdata)<-c('PatientGuid','dmIndicator')\n",
    "write.csv(sentdata, file=\"c://dmii/models/gbm20_5_0.0025_0.80_40.csv\", row.names = FALSE) \n",
    "## cv fold predictions set for stacking models\n",
    "cvestim<-cbind(as.character(Patient2$PatientGuid),exp(gbm20_5_0.0025_0.80_40$fold.fit)/(1+exp(gbm20_5_0.0025_0.80_40$fold.fit)))\n",
    "colnames(cvestim)<-c('PatientGuid','gbm20_5_0.0025_0.80_40')\n",
    "write.csv(cvestim,file=\"c://dmii/models/gbm20_5_0.0025_0.80_40_cvest.csv\", row.names = FALSE)\n",
    "\n",
    "#  Model 1\n",
    "set.seed(223646)\n",
    "gbm20_5_0.0025_0.80_20<-gbm.step(Patient2,gbm.x=c(3:ncol(Patient2)),gbm.y=2,\n",
    "tree.complexity=5,\n",
    "n.folds=20,n.trees=50, learning.rate=0.0025,bag.fraction=0.80,n.minobsinnode=20,tolerance = 0.0005,\n",
    "family=\"bernoulli\",max.trees=30000,keep.fold.models = TRUE, keep.fold.vector = TRUE, keep.fold.fit=TRUE)\n",
    "save(gbm20_5_0.0025_0.80_20,file=\"c://dmii/models/gbm20_5_0.0025_0.80_20.RData\",compress=TRUE)\n",
    "pred<-predict.gbm(gbm20_5_0.0025_0.80_20,Patient[Patient$dmIndicator==-1,dmii],n.trees=gbm20_5_0.0025_0.80_20$gbm.call$best.trees,type=\"response\")\n",
    "sentdata<- cbind(as.character(Patient$PatientGuid[Patient$dmIndicator==-1]),as.numeric(pred)) \n",
    "colnames(sentdata)<-c('PatientGuid','dmIndicator')\n",
    "write.csv(sentdata, file=\"c://dmii/models/gbm20_5_0.0025_0.80_20.csv\", row.names = FALSE) \n",
    "## cv fold predictions set for stacking models\n",
    "cvestim<-cbind(as.character(Patient2$PatientGuid),exp(gbm20_5_0.0025_0.80_20$fold.fit)/(1+exp(gbm20_5_0.0025_0.80_20$fold.fit)))\n",
    "colnames(cvestim)<-c('PatientGuid','gbm20_5_0.0025_0.80_20')\n",
    "write.csv(cvestim,file=\"c://dmii/models/gbm20_5_0.0025_0.80_20_cvest.csv\", row.names = FALSE)\n",
    " \n",
    "#Model H\n",
    "set.seed(223646)\n",
    "gbm10_5_0.0025_0.80_30_tolhalf<-gbm.step(Patient2,gbm.x=c(3:ncol(Patient2)),gbm.y=2,\n",
    "tree.complexity=5,\n",
    "n.folds=10,n.trees=50, learning.rate=0.0025,bag.fraction=0.80,n.minobsinnode=30,tolerance = 0.0005,\n",
    "family=\"bernoulli\",max.trees=30000,keep.fold.models = TRUE, keep.fold.vector = TRUE, keep.fold.fit=TRUE)\n",
    "save(gbm10_5_0.0025_0.80_30_tolhalf,file=\"c://dmii/models/gbm10_5_0.0025_0.80_30_tolhalf.RData\",compress=TRUE)\n",
    "pred<-predict.gbm(gbm10_5_0.0025_0.80_30_tolhalf,Patient[Patient$dmIndicator==-1,dmii],n.trees=gbm10_5_0.0025_0.80_30_tolhalf$gbm.call$best.trees,type=\"response\")\n",
    "sentdata<- cbind(as.character(Patient$PatientGuid[Patient$dmIndicator==-1]),as.numeric(pred)) \n",
    "colnames(sentdata)<-c('PatientGuid','dmIndicator')\n",
    "write.csv(sentdata, file=\"c://dmii/models/gbm10_5_0.0025_0.80_30_tolhalf.csv\", row.names = FALSE) \n",
    "save(gbm10_5_0.0025_0.80_30_tolhalf,file=\"c://dmii/models/gbm10_5_0.0025_0.80_30_tolhalf.RData\",compress=TRUE)\n",
    "## cv fold predictions set for stacking models\n",
    "cvestim<-cbind(as.character(Patient2$PatientGuid),exp(gbm10_5_0.0025_0.80_30_tolhalf$fold.fit)/(1+exp(gbm10_5_0.0025_0.80_30_tolhalf$fold.fit)))\n",
    "colnames(cvestim)<-c('PatientGuid','gbm10_5_0.0025_0.80_30_tolhalf')\n",
    "write.csv(cvestim,file=\"c://dmii/models/gbm10_5_0.0025_0.80_30_tolhalf_cvest.csv\", row.names = FALSE)\n",
    "\n",
    "#Model E\n",
    "set.seed(223646)\n",
    "gbm10_5_0.0025_0.80_30<-gbm.step(Patient2,gbm.x=c(3:ncol(Patient2)),gbm.y=2,\n",
    "tree.complexity=5,\n",
    "n.folds=10,n.trees=50, learning.rate=0.0025,bag.fraction=0.80,n.minobsinnode=30,tolerance = 0.001,\n",
    "family=\"bernoulli\",max.trees=30000,keep.fold.models = TRUE, keep.fold.vector = TRUE, keep.fold.fit=TRUE)\n",
    "save(gbm10_5_0.0025_0.80_30,file=\"c://dmii/models/gbm10_5_0.0025_0.80_30.RData\",compress=TRUE)\n",
    "pred<-predict.gbm(gbm10_5_0.0025_0.80_30,Patient[Patient$dmIndicator==-1,dmii],n.trees=gbm10_5_0.0025_0.80_30$gbm.call$best.trees,type=\"response\")\n",
    "sentdata<- cbind(as.character(Patient$PatientGuid[Patient$dmIndicator==-1]),as.numeric(pred)) \n",
    "colnames(sentdata)<-c('PatientGuid','dmIndicator')\n",
    "write.csv(sentdata, file=\"c://dmii/models/gbm10_5_0.0025_0.80_30.csv\", row.names = FALSE) \n",
    "save(gbm10_5_0.0025_0.80_30,file=\"c://dmii/models/gbm10_5_0.0025_0.80_30.RData\",compress=TRUE)\n",
    "## cv fold predictions set for stacking models\n",
    "cvestim<-cbind(as.character(Patient2$PatientGuid),exp(gbm10_5_0.0025_0.80_30$fold.fit)/(1+exp(gbm10_5_0.0025_0.80_30$fold.fit)))\n",
    "colnames(cvestim)<-c('PatientGuid','gbm10_5_0.0025_0.80_30')\n",
    "write.csv(cvestim,file=\"c://dmii/models/gbm10_5_0.0025_0.80_30_cvest.csv\", row.names = FALSE)\n",
    "\n",
    "### Models with a few more features (really not necesaries)\n",
    "\n",
    "Patient2<-Patient[Patient$dmIndicator!=-1,c(dmii,exten)]\n",
    "\n",
    "#Model A\n",
    "set.seed(223646)\n",
    "gbm10_5_0.0025_0.80_30_tolhalf_ext<-gbm.step(Patient2,gbm.x=c(3:ncol(Patient2)),gbm.y=2,\n",
    "tree.complexity=5,\n",
    "n.folds=10,n.trees=50, learning.rate=0.0025,bag.fraction=0.80,n.minobsinnode=30,tolerance = 0.0005,\n",
    "family=\"bernoulli\",max.trees=30000,keep.fold.models = TRUE, keep.fold.vector = TRUE, keep.fold.fit=TRUE)\n",
    "save(gbm10_5_0.0025_0.80_30_tolhalf_ext,file=\"c://dmii/models/gbm10_5_0.0025_0.80_30_tolhalf_ext.RData\",compress=TRUE)\n",
    "pred<-predict.gbm(gbm10_5_0.0025_0.80_30_tolhalf_ext,Patient[Patient$dmIndicator==-1,c(dmii,exten)],n.trees=gbm10_5_0.0025_0.80_30_tolhalf_ext$gbm.call$best.trees,type=\"response\")\n",
    "sentdata<- cbind(as.character(Patient$PatientGuid[Patient$dmIndicator==-1]),as.numeric(pred)) \n",
    "colnames(sentdata)<-c('PatientGuid','dmIndicator')\n",
    "write.csv(sentdata, file=\"c://dmii/models/gbm10_5_0.0025_0.80_30_tolhalf_ext.csv\", row.names = FALSE) \n",
    "## cv fold predictions set for stacking models\n",
    "cvestim<-cbind(as.character(Patient2$PatientGuid),exp(gbm10_5_0.0025_0.80_30_tolhalf_ext$fold.fit)/(1+exp(gbm10_5_0.0025_0.80_30_tolhalf_ext$fold.fit)))\n",
    "colnames(cvestim)<-c('PatientGuid','gbm10_5_0.0025_0.80_30_tolhalf_ext')\n",
    "write.csv(cvestim,file=\"c://dmii/models/gbm10_5_0.0025_0.80_30_tolhalf_ext_cvest.csv\", row.names = FALSE)\n",
    "\n",
    "#Model D\n",
    "set.seed(223646)\n",
    "gbm10_5_0.0025_0.80_30_ext<-gbm.step(Patient2,gbm.x=c(3:ncol(Patient2)),gbm.y=2,\n",
    "tree.complexity=5,\n",
    "n.folds=10,n.trees=50, learning.rate=0.0025,bag.fraction=0.80,n.minobsinnode=30,tolerance = 0.001,\n",
    "family=\"bernoulli\",max.trees=30000,keep.fold.models = TRUE, keep.fold.vector = TRUE, keep.fold.fit=TRUE)\n",
    "save(gbm10_5_0.0025_0.80_30_ext,file=\"c://dmii/models/gbm10_5_0.0025_0.80_30_ext.RData\",compress=TRUE)\n",
    "pred<-predict.gbm(gbm10_5_0.0025_0.80_30_ext,Patient[Patient$dmIndicator==-1,c(dmii,exten)],n.trees=gbm10_5_0.0025_0.80_30_ext$gbm.call$best.trees,type=\"response\")\n",
    "sentdata<- cbind(as.character(Patient$PatientGuid[Patient$dmIndicator==-1]),as.numeric(pred)) \n",
    "colnames(sentdata)<-c('PatientGuid','dmIndicator')\n",
    "write.csv(sentdata, file=\"c://dmii/models/gbm10_5_0.0025_0.80_30_ext.csv\", row.names = FALSE) \n",
    "## cv fold predictions set for stacking models\n",
    "cvestim<-cbind(as.character(Patient2$PatientGuid),exp(gbm10_5_0.0025_0.80_30_ext$fold.fit)/(1+exp(gbm10_5_0.0025_0.80_30_ext$fold.fit)))\n",
    "colnames(cvestim)<-c('PatientGuid','gbm10_5_0.0025_0.80_30_ext')\n",
    "write.csv(cvestim,file=\"c://dmii/models/gbm10_5_0.0025_0.80_30_ext_cvest.csv\", row.names = FALSE)\n",
    " \n",
    "#Model B\n",
    "set.seed(223646)\n",
    "gbm10_5_0.003_0.80_30_tolhalf_ext<-gbm.step(Patient2,gbm.x=c(3:ncol(Patient2)),gbm.y=2,\n",
    "tree.complexity=5,\n",
    "n.folds=10,n.trees=50, learning.rate=0.003,bag.fraction=0.80,n.minobsinnode=30,tolerance = 0.0005,\n",
    "family=\"bernoulli\",max.trees=30000,keep.fold.models = TRUE, keep.fold.vector = TRUE, keep.fold.fit=TRUE)\n",
    "save(gbm10_5_0.003_0.80_30_tolhalf_ext,file=\"c://dmii/models/gbm10_5_0.003_0.80_30_tolhalf_ext.RData\",compress=TRUE)\n",
    "pred<-predict.gbm(gbm10_5_0.003_0.80_30_tolhalf_ext,Patient[Patient$dmIndicator==-1,c(dmii,exten)],n.trees=gbm10_5_0.003_0.80_30_tolhalf_ext$gbm.call$best.trees,type=\"response\")\n",
    "sentdata<- cbind(as.character(Patient$PatientGuid[Patient$dmIndicator==-1]),as.numeric(pred)) \n",
    "colnames(sentdata)<-c('PatientGuid','dmIndicator')\n",
    "write.csv(sentdata, file=\"c://dmii/models/gbm10_5_0.003_0.80_30_tolhalf_ext.csv\", row.names = FALSE) \n",
    "## cv fold predictions set for stacking models\n",
    "cvestim<-cbind(as.character(Patient2$PatientGuid),exp(gbm10_5_0.003_0.80_30_tolhalf_ext$fold.fit)/(1+exp(gbm10_5_0.003_0.80_30_tolhalf_ext$fold.fit)))\n",
    "colnames(cvestim)<-c('PatientGuid','gbm10_5_0.003_0.80_30_tolhalf_ext')\n",
    "write.csv(cvestim,file=\"c://dmii/models/gbm10_5_0.003_0.80_30_tolhalf_ext_cvest.csv\", row.names = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**===================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Scientist B**\n",
    "\n",
    "#PHASE IV: Modeling\n",
    "\n",
    "######Select Modeling Technique\n",
    "This section refers to the specific modeling technique.\n",
    "\n",
    "1. Modeling technique\n",
    "    * Document the actual modeling technique that is to be used:\n",
    "2. Modeling assumptions\n",
    "    * Record the assumption that the model makes about the data:\n",
    "\n",
    "######Generate Test Design\n",
    "Describe how we plan to test the model's quality and validity of the model.\n",
    "\n",
    "1. Test design\n",
    "    * Describe the plan for training:\n",
    "    * Describe the plan for testing:\n",
    "    * Describe the plan for evaluating models:\n",
    "\n",
    "######Build Model\n",
    "Run the modeling tool on the prepared dataset to create one or more models.\n",
    "\n",
    "1. Parameter settings\n",
    "    * List the parameters and their chosen values, along with the choice of parameters settings:\n",
    "2. Models\n",
    "    * These are the actual models produced by the modeling tool, not a report.\n",
    "3. Model description\n",
    "    * Describe the resulting models. Report on the interpretation of the models and document any difficulties encountered with their meanings.\n",
    "\n",
    "######Assess Model\n",
    "The Data Scientist ranks models according to the evaluation criteria. As much as possible, business objective and business success criteria should be taken into account.\n",
    "\n",
    "1. Model assessment\n",
    "    * Summarize results of this task, list quality of generated models (in terms of accuracy and quality):\n",
    "    \n",
    "2. Revised paramter settings\n",
    "    * Revised parameter settings and tune them for the next run in the build model task:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************************\n",
    "#Exercise 5\n",
    "\n",
    "Choose between A and B.\n",
    "***************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Scientist A**\n",
    "\n",
    "#PHASE V: Evaluation\n",
    "\n",
    "######Evaluate Results\n",
    "This step is meant to evaluate the model from a business perspective and seeks to determine if there is some business reason why this model is deficient. \n",
    "\n",
    "1. Assessment of Data Science results\n",
    "    * Summarize assessment results in terms of business criteria:\n",
    "2. Approved models\n",
    "    * A list of generated models which are approved for business reasons:\n",
    "\n",
    "######Review Process\n",
    "This step is a quality assurance step insuring we used all the the appropriate items in the models.\n",
    "\n",
    "1. Review of process\n",
    "    * Summarize the process review and highlight activities that have been missed and those that should be repeated.\n",
    "\n",
    "######Determine Next Steps\n",
    "Team decides whether to finish the project and move on to deployment, initiate further iterations, or set up new data science projects. \n",
    "\n",
    "1. List of possible actions\n",
    "    * Reasons for each option:\n",
    "    * Reasons against each option:\n",
    "    \n",
    "2. Decisions\n",
    "    * How to proceed, along with rationale:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**===================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Scientist B**\n",
    "\n",
    "#PHASE V: Evaluation\n",
    "\n",
    "######Evaluate Results\n",
    "1. Assessment of Data Science results\n",
    "    *  Our organization felt that we were unable to capture most of the diabetic type II population through standard channels and that by developing a predictive model which could classify patients with a high-likelihood of type II diabetes that could reduce cost and increase quality of care to patients. Currently our organization does not have any predictive model built for this. However, the models we constructed are able to produce a result of 0.31490 which is far lower than the 0.40 benchmark set by the business to be useful.\n",
    "\n",
    "2. Approved models\n",
    "\n",
    "Below is our list of approved models: \n",
    "\n",
    "***Gradient Boosting Machine***\n",
    "\n",
    "GBM Model | CV Error | Folds | Trees | Depth | Shrinkage | Bag Frac | Node Size | Tolerance\n",
    "-|-|-|-|-|-|-|-\n",
    "    gbm 10_5 0.003_0.80_30 | 0.31210 | 10|7,550| 5 | 0.003|0.80|30|0.001\n",
    "    gbm10_5_0.003_0.80_30_tolhalf_ext |\t0.31153|\t10|\t8,500|\t5|\t0.003|\t0.80|\t30|\t0.0005\n",
    "    gbm10_5_0.0025_0.80_30\t|0.31319\t|10\t|8,000|\t5|\t0.003|\t0.80|\t30|\t0.001\n",
    "    gbm10_5_0.0025_0.80_30_ext|\t0.31312\t|10|\t7,750|\t5|\t0.0025|\t0.80|\t30|\t0.001\n",
    "    gbm10_5_0.0025_0.80_30_tolhalf\t|0.31122\t|10\t|11,000|\t5|\t0.0025|\t0.80|\t30|\t0.0005\n",
    "    gbm10_5_0.0025_0.80_30_tolhalf_ext\t|0.31139|\t10\t|10,450|\t5|\t0.0025|\t0.80|\t30|\t0.0005\n",
    "    gbm20_5_0.002_0.80_10\t|0.31049\t|20|\t13,450|\t5\t|0.002|\t0.80|\t10|\t0.001\n",
    "    gbm20_5_0.002_0.80_15\t|0.31040\t|20\t|12,950\t|5\t|0.002\t|0.80\t|15\t|0.001\n",
    "    gbm20_5_0.0025_0.80_20\t|0.30878\t|20\t|12,300\t|5\t|0.0025\t|0.80\t|20\t|0.001\n",
    "    gbm20_5_0.0025_0.80_40\t|0.31040\t|20\t|10,500\t|5\t|0.0025\t|0.80\t|40\t|0.001\n",
    "    gbm20_6_0.002_0.80_30\t|0.30931\t|20\t|12,200\t|6\t|0.002\t|0.80\t|30\t|0.001\n",
    "\n",
    "    \n",
    "***Random Forest***\n",
    "\n",
    "RF Model | OOB MSE | Trees | Node Size\n",
    "-|-|-|-\n",
    "    RF1 | 0.10055| 15,000 | 5\n",
    "    RF5\t|0.10076|\t30,000|\t15\n",
    "    RF2\t|0.10089|\t15,000|\t20\n",
    "    RF3\t|0.10102|\t15,000|\t40\n",
    "\n",
    "######Review Process\n",
    "* We have gone back through each step to confirm that we were able to reproduce the results described. No activities have been missed or repeated. \n",
    "    \n",
    "######Determine Next Steps\n",
    "\n",
    "1. List of possible actions\n",
    "    * Reasons for each option:\n",
    "        * We could move forward with the completion of the Type II Diabetes model\n",
    "        * We could stop the Type II Diabetes model\n",
    "        * We could develop faster learning models\n",
    "    * Reasons against each option:\n",
    "        * Moving forward could mean we miss a significantly more accurate model\n",
    "        * Stopping the Type II model at this point would not accomplish the business goal of uncovering these population, reducing cost, and improving healthcare quality.\n",
    "        * The business concern was not about building faster models, but meeting the accuracy benchmark of 0.40 logloss. Developing faster learning models would take additional company resources and with no guarantee of besting the predictive accuracy of the model already developed.\n",
    "    \n",
    "2. Decisions\n",
    "    * We recommend placing in production our Type II Diabetes model as it meets both the business and data science objectives set out at the start of the project. This model will help to uncover populations with Type II Diabetes which have gone under diagnosed and our organization can reduce cost and improve patient care by discovering patients in this subclassification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************************\n",
    "#Exercise 6\n",
    "\n",
    "Choose between A and B.\n",
    "***************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Scientist A**\n",
    "\n",
    "#PHASE VI: Deployment\n",
    "\n",
    "######Plan Deployment\n",
    "Takes the evaluation results and determines a strategy for deployment. \n",
    "\n",
    "Once leadership has approved the models that the data science department has built, we will work with IT to begin the process of integrating the models in the ACME healthcare processing pipeline. We will insure that the preprocessing steps we have developed is put into place. \n",
    "\n",
    "All modeling files are stored on the share drive. \n",
    " \n",
    "######Plan Monitoring and Maintenance\n",
    "\n",
    "**Monitor and Maintenance Plan**\n",
    "\n",
    "Since we cannot assume that the correct target feature value for a query instance will be made available shortly after the query has been presented to a deployed model, we will use the stability index. The stability index is an alternative to using the changing model performance by monitoring changes in the distribution of model output as a signal of concept drift. \n",
    "\n",
    "In order to compare distribution, we measure the distribution of model outputs on the test set that was used to originally evaluate a model and hte repeat this measurement on new sets of query instances collected during periods after the model has been deployed. \n",
    "\n",
    "One of the most commonly used measures for this is the stability index. The stability index is calculate as:\n",
    "\n",
    "$$stability\\space index = \\sum_{l\\in levels(t)}^{}((\\frac{\\left |A_{t=l}\\right |}{\\left | A \\right |}-\\frac{\\left | B_{t=l} \\right |}{\\left | B \\right |})\\times log_{e}(\\frac{\\left | A_{t=l} \\right |}{\\left | A \\right |} / \\frac{\\left | B_{t=l} \\right |}{\\left | B \\right |}))$$\n",
    "\n",
    "where $$\\left | A \\right |$$ refers to the size of the test set on which performance measures were originally calculated, \n",
    "\n",
    "$$\\left | A_{t=l} \\right |$$ \n",
    "\n",
    "refers to the number of instances in the original test set for which the model made a prediction of level $$l$$ for target $$t$$\n",
    "$$\\left | B \\right |$$ and $$\\left | B_{t=l} \\right |$$ refer to the same measurements on the newly collected dataset\n",
    "$$log_{e}$$ is the natural logarithm.\n",
    "\n",
    "* Other important points:\n",
    "    * If the value of the stability index is less than 0.1, then the distribution of the newly collected test set is broadly similar to the distribution in the original test set. \n",
    "    * If the value of the stability index is between 0.1 and 0.25, then some change has occurred and further investigation may be useful.\n",
    "    * A stability index value greater than 0.25 suggests that a significant change has occurred and corrective action is required. \n",
    "    \n",
    "We recommend an alert system be put in place and work with the above threshold so that an individual from the data science department could consider retraining the model.\n",
    "\n",
    "    \n",
    "######Produce Final Report\n",
    "**Final report & Presentation**\n",
    "We have archived a final comprehensive presentation of the data science results for this project located on ***S:\\Data Science Projects\\Type II Diabetes***. This report includes all previous deliverables and summarizes the results.\n",
    "\n",
    "######Review Project\n",
    "* Experience documentation\n",
    "    * We gained more understanding of what it is like to coordinate with the IT department when they have ongoing engagements. We assumed they would be able to assist us in the data integration of all the various tables. However, they had prior engagements that pushed our request back 30-days. In the future, we will know what is required of them and confirm their availability. \n",
    "    * We only spent 5% of our time on feature engineering and feature selection combined - this was not sufficient. We would like to make modifications to our work-flow to be able to spending 10% of our time on feature engineering and another 10% of our time on feature selection. Beyond the preprocessing of data we felt that this data science project really requires more attention to these areas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**===================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Scientist B**\n",
    "\n",
    "#PHASE VI: Deployment\n",
    "\n",
    "######Plan Deployment\n",
    "Takes the evaluation results and determines a strategy for deployment. \n",
    "\n",
    "1. Deployment plan\n",
    "    * Summarize the deployment strategy, including the necessary steps and how to perform them:\n",
    "    \n",
    "######Plan Monitoring and Maintenance\n",
    "Develop a careful monitoring and maintenance strategy.\n",
    "\n",
    "1. Monitoring and maintenance plan\n",
    "    * Summarize the monitoring and maintenance strategy, including the necessary steps and how to perform them.\n",
    "    \n",
    "######Produce Final Report\n",
    "This could be a final comprehensive presentation of the data science results or a summary of the project and its experiences.\n",
    "\n",
    "1. Final report\n",
    "    * A written report of the data science engagement. It includes all of the previous deliverables, summarizing and organizing the results:\n",
    "    \n",
    "2. Final presentation\n",
    "    * Results presented to the client:\n",
    "\n",
    "######Review Project\n",
    "Assess what went right and what went wrong, what was done well and what needs to be improved.\n",
    "\n",
    "1. Experience documentation\n",
    "    * Summarize important experience gained during the project (pitfalls, misleading approaches, or hints for selecting the data science techniques in similar situations could be part of this documentation):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--bibtex\n",
    "@book{calicoww2:2,\n",
    "    title = {Rebuilding Calico},\n",
    "    author = {Kepps, Milo},\n",
    "    year = {2002},\n",
    "    publisher = {Python Books}\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Patient Features\n",
    "These features were derived from the transcript table:\n",
    "* Age\n",
    "* BodyMassIndex\n",
    "* Weight\n",
    "* MaxWeight\n",
    "* MinWeight\n",
    "* DiastolicBP\n",
    "* SystolicBP\n",
    "\n",
    "####Diagnostic Features\n",
    "* These features were derived from the diagnosis table.\n",
    "    * ICD9\n",
    "    * HasAlzheimers\n",
    "    * HadStroke\n",
    "    * HasMixedHyperlipidemia\n",
    "    * HasRenalDisease\n",
    "    \n",
    "* Counts for diagnosis codes that were being treated with medications:\n",
    "    * MedDxHasCongestiveHeartFailure\n",
    "    * MedDxHasDepression\n",
    "    * MedDxHasHyperlipidemia\n",
    "    * MedDxHasRenalDisease\n",
    "    * MedICD9_01\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##How to Generate My Model\n",
    "\n",
    "**Copy files in c:\\dmii\\**\n",
    "    \n",
    "* DMfeatureCreation.R\n",
    "* DMgbm.R\n",
    "* DMrandomforest.R\n",
    "* DMstacking.R\n",
    "* gbm.step.R\n",
    "* gbm.utils.R\n",
    "\n",
    "**Copy in c:\\dmii\\data**\n",
    "\n",
    "* compData.db\n",
    "* drugsap.csv\n",
    "* icd9.csv\n",
    "\n",
    "**Create c:\\dmii\\models** for outputs\n",
    "\n",
    "Run the source files in this order:\n",
    "\n",
    "* DMfeatureCreation.R\n",
    "* DMgbm.R\n",
    "* DMrandomforest.R\n",
    "* DMstacking.R\n",
    "\n",
    "The code is split into the following files:\n",
    "*DMfeatureCreation.R*\n",
    "Connect compData.db, clean the data and create features. \n",
    "\n",
    "The output is file Patient.csv.\n",
    "*DMgbm.R*\n",
    "Read *Patient.csv* file and fit the boosted trees models. The cross-validation stopping is controlled with dismo wrapper.\n",
    "As output the model is saved in RData format, and in csv format the predictions of test set and the CV folds predictions of train set for model stacking (the latter with cvest suffix in filename).\n",
    "\n",
    "*DMrandomforest.R*\n",
    "Read *Patient.csv* file and fit the random forest models.\n",
    "\n",
    "As output the model is saved in RData format, and in csv format the predictions of test set and the OOB predictions of train set for model stacking (the latter with cvest suffix in filename).\n",
    "\n",
    "*DMstacking.R*\n",
    "Do the stacking of the models using a generalized additive model (gam) with cubic splines.\n",
    "Read CV and OOB predictions of training set, fit the gam and do a prediction for test set saved as dmpredict.csv file.\n",
    "\n",
    "*gbm.step.R* and *gbm.utils.R*\n",
    "Used for add n.minobsinnode parameter in the gbm.step wrapper of the dismo package. Dismo use the default for this parameter (n=10) and in small data sets with relatively big number of features increase the overfitting risk.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
